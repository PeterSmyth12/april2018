{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas?\n",
    "\n",
    "pandas is a Python library containing a set of functions and specialised data structures that have been designed to help Python programmers to perform data analysis tasks in a structured way.\n",
    "\n",
    "Most of the things that pandas can do can be done with basic Python, but the collected set of pandas functions and data structure makes the data analysis tasks more consistent in terms of syntax and therefore aids readabilty.\n",
    "\n",
    "Particular features of pandas that we will be looking at include:\n",
    "\n",
    "\n",
    "* Reading csv files\n",
    "* Select specific columns\n",
    "* Select specific rows\n",
    "* Provide simple summary statistics on numeric columns\n",
    "* Aggregation across columns\n",
    "* Creating new columns\n",
    "* Simple plotting of data\n",
    "\n",
    "\n",
    "\n",
    "## Importing the pandas library\n",
    "\n",
    "Importing the pandas library is done in exactly the same way as for any other library. In almost all examples of Python code using the pandas library, it will have been imported and given an alias of 'pd'. Who are we to break with tradition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas data structures\n",
    "\n",
    "There are 2 main data structure used by pandas , they are the Series and the Dataframe. The Series equates in general to a vector or a list. The data frame is equivalent to a table. Each column in a pandas dataframe is a pandas Series data structure.\n",
    "\n",
    "We will mainly be looking at the Dataframe. \n",
    "\n",
    "\n",
    "Dataframes can be created directly in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
    "columns=['A', 'B'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is however more usual to create a Pandas dataframe by reading a csv file.\n",
    "\n",
    "## Reading a csv file\n",
    "\n",
    "When we read a csv dataset in base Python we did so by opening the dataset, reading and processing a record at a time and then closing the dataset after we had read the last record. Reading dataset's in this way is slow and places all of the responsibility for extracting individual data items of information from the records on the programmer. \n",
    "\n",
    "The main advantage of this approach, however, is that you only have to store one dataset record in memory at a time. This means that if you have the time, you can process datasets of arbitarily large sizes.\n",
    "\n",
    "In Pandas, csv files are read as complete datasets. You do not have to explicitly open and close the dataset. All of the dataset records are assembled into a dataframe. If your dataset has column headers in the first record then these can be used as the dataframe column names. You can explicitly state this in the parameters to the call, but Pandas is usually able to infer that there ia a header row and use it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(\"D:\\\\Intro_to_programming_09042018\\\\data\\\\geog.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get various information about the newly created dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first 5 lines \n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "my_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rows only - another use of the len function\n",
    "len(my_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first and lat few rows. If there was a lot of columns you would only get the first and last few of those as well\n",
    "my_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count number of Not NA or missing values for each variable\n",
    "my_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of unique values for a specific column\n",
    "print(len(my_df['NUTS4'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of columns\n",
    "my_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or alternatively as a proper list\n",
    "list(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can iterate over the list to get information on the individual columns\n",
    "for x in list(my_df) :\n",
    "    print(len(my_df[x].unique()), \"\\t\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# values of specific column\n",
    "print(my_df.ACORN_Category.unique())\n",
    "\n",
    "# values of specific column\n",
    "print(my_df.fuelTypes.unique())\n",
    "\n",
    "# values of specific column\n",
    "x = my_df.fuelTypes.unique()[0]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An alternative way of specifying the column name\n",
    "\n",
    "y = my_df['ACORN_Category'].unique()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count of each value in column  - without using group_by\n",
    "\n",
    "a = my_df.fuelTypes.value_counts()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for numeric columns, you can get basic statistics\n",
    "# The warning is because there are a few missing values\n",
    "\n",
    "my_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select rows based on column criteria\n",
    "\n",
    "my_df[my_df['ACORN_Category'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select rows based on column criteria\n",
    "\n",
    "my_df[my_df['anonID'] < 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rows containing missing values can be removed by using the dropna method\n",
    "\n",
    "print(my_df.count())\n",
    "print(\"\\n\\n\")\n",
    "my_df = my_df.dropna()\n",
    "print(my_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now run the describe again\n",
    "# for numeric columns, you can get basic statistics\n",
    "# no warning because there are now no missing values\n",
    "\n",
    "my_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more complex selections\n",
    "\n",
    "my_df[my_df.ACORN_Category == 6]\n",
    "\n",
    "#my_df[(my_df.anonID <= 10) & (my_df.ACORN_Group == 'M')]\n",
    "\n",
    "#my_df[(my_df.anonID <= 10) & (my_df.ACORN_Group == 'M')][['anonID', 'fuelTypes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# values of specific column\n",
    "\n",
    "my_df.ACORN_Group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(my_df.groupby(\"ACORN_Group\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group by specific column and count of values\n",
    "x = my_df.groupby(\"ACORN_Category\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a new column\n",
    "\n",
    "my_df['Tout_Total']  = my_df.Elec_Tout + my_df.Gas_Tout\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deleting a column\n",
    "\n",
    "del my_df['Tout_Total']\n",
    "\n",
    "# or\n",
    "\n",
    "#my_df.drop('Tout_Total', 1)\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The simple plotting functions of Pandas, make use of the Matplotlib package, so it has to be loaded.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of ACORN_Category\n",
    "\n",
    "my_df['ACORN_Category'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "\n",
    "my_df.plot.scatter(x='ACORN_Category', y='ACORN_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
